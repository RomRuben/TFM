In the first documentation round, i found the following info about language detection.

## Language Detection


* **[Language-Detection] (https://github.com/shuyo/language-detection)**: This is a language detection library implemented in plain Java. Generate language profiles from Wikipedia abstract xml, Detect language of a text using naive Bayesian filter, 99% over precision for 53 languages.

> The library that we used in the docpath project.

* **[Language Identification tools] (odur.let.rug.nl/~vannoord/TextCat/competitors.html)**: A list of language identification tools. Related link ([Language Identification tools] (www.soft-switch.org/downloads/speech/lang_guess/lang_guess/competitors.html)).

> This site classifies the tools by number of languages supported and license.

* **[Language Identification Tools] (www.aclweb.org/aclwiki/index.php?title=Language_Identification_Tools):** A listing of language identification tools. Language identification can mean both identifiying text type (e.g. news vs literature) and language (e.g. English vs Frisian vs Dutch). Most of these tools require training on a big corpus (see [List of resources by language](http://www.aclweb.org/aclwiki/index.php?title=List_of_resources_by_language)  for corpora per language), but many come with some prebuilt language models.

> This site classifies the tools by solving strategy.

* **[Langid.py] (https://github.com/saffsd/langid.py)**: Stand-alone language identification system.

* **[Wikipedia Entry: Language Identification] (https://en.wikipedia.org/wiki/Language_identification)** : Wikipedia page about Language identification.

> This wikipedia entry has a list of most popular libraries and web services used for language identification.

* **[ANTLR] (www.antlr.org/download.html)**: ANTLR (ANother Tool for Language Recognition) is a powerful parser generator for reading, processing, executing, or translating structured text or binary files. It's widely used to build languages, tools, and frameworks. From a grammar, ANTLR generates a parser that can build and walk parse trees.

> Interesting tool.

-----------


This is the candidate frameworks:

## Language Detection

* **[Language-Detection] (https://github.com/shuyo/language-detection)**: This is a language detection library implemented in plain Java. Generate language profiles from Wikipedia abstract xml, Detect language of a text using naive Bayesian filter, 99% over precision for 53 languages. (**must**).
* **[Textcat for Java] (http://textcat.sourceforge.net/)** : The text analysis algorithm is based on the classification technique described in Cavnar & Trenkle, "N-Gram-Based Text Categorization".  Also : http://software.wise-guys.nl/libtextcat/.
* **[Textcat for Python] (http://thomas.mangin.com/data/source/ngram.py)** : An simple script with the textcat language detection process.
* **[Langid.py] (https://github.com/saffsd/langid.py)**.
* **[Guess Language] (https://bitbucket.org/spirit/guess_language)**.
* **[Nutch LanguageIdentifier](https://wiki.apache.org/nutch/LanguageIdentifier)**.
* **[cld.js] (https://github.com/jaukia/cld-js)** : Detect the langugage of any piece of text â€” the text goes in and a language comes out. This is a Javascript port of the Compact Language Detector from Chromium.
* **[LC4J] (olivo.net/2009/08/lc4j/)**.
* **[ANTLR] (http://www.antlr.org/download.html)**.
